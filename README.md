# Supervised Machine Learning: Regression and Classification

This repository documents my learning journey through the **Supervised Machine Learning: Regression and Classification** course, an online non-credit course authorized by **DeepLearning.AI and Stanford University** and offered through **Coursera**.

## Course Overview
This course provides a comprehensive introduction to supervised machine learning, covering essential concepts, techniques, and hands-on coding implementations. The curriculum includes linear and logistic regression, gradient descent, overfitting, regularization, and performance optimization techniques.

---

## Week 1: Introduction to Machine Learning
### Topics Covered:
- Introduction to supervised and unsupervised learning
- Key applications of machine learning in various fields
- Basic structure of machine learning models
- Overview of datasets and training/testing splits
- Introduction to cost functions and optimization

### Practical Work:
- Explored different types of machine learning (Supervised vs. Unsupervised)
- Implemented basic regression models using Python

### Assessments:
- **Practice Quiz:** Supervised vs. Unsupervised Learning
- **Practice Quiz:** Regression
- **Practice Quiz:** Train the Model with Gradient Descent

---

## Week 2: Regression with Multiple Input Variables
### Topics Covered:
- Extending linear regression to multiple features (Multivariable Linear Regression)
- Vectorization and matrix representation for efficient computation
- Feature scaling to improve gradient descent convergence
- Feature engineering and polynomial regression

### Practical Work:
- Implemented multiple linear regression with Python and NumPy
- Applied feature scaling and normalization techniques

### Assessments:
- **Practice Quiz:** Multiple Linear Regression
- **Practice Quiz:** Gradient Descent in Practice
- **Practice Lab:** Implementing Linear Regression in Code

---

## Week 3: Classification
### Topics Covered:
- Introduction to classification problems
- Logistic regression and sigmoid function
- Cost function for logistic regression
- Gradient descent for logistic regression
- Overfitting and regularization techniques (L1 & L2 Regularization)

### Practical Work:
- Implemented logistic regression using Python
- Applied regularization to handle overfitting
- Evaluated classification model performance

### Assessments:
- **Practice Quiz:** Classification with Logistic Regression
- **Practice Quiz:** Cost Function for Logistic Regression
- **Practice Quiz:** Gradient Descent for Logistic Regression
- **Practice Quiz:** The Problem of Overfitting
- **Practice Lab:** Implementing Logistic Regression with Regularization

---

## Key Takeaways
- **Regression Analysis:** Implemented linear and multiple linear regression models and optimized them using gradient descent.
- **Feature Engineering:** Applied feature scaling, polynomial regression, and vectorization techniques to improve model efficiency.
- **Classification Models:** Built logistic regression models for binary classification problems and tackled overfitting with regularization.
- **Hands-on Coding:** Gained experience in implementing machine learning algorithms using Python, NumPy, and related libraries.

This course strengthened my understanding of supervised learning and provided a solid foundation for further studies in machine learning and data science.

---

## Technologies Used
- Python
- NumPy
- Pandas
- Matplotlib/Seaborn (for visualization)

### Next Steps
- Exploring more advanced machine learning topics such as Neural Networks and Deep Learning.
- Applying these concepts to real-world datasets for deeper understanding.
- Continuing my journey with machine learning and AI research.

### References
- [Supervised Machine Learning: Regression and Classification (Coursera)](https://coursera.org/share/55933d8d53a910dbc5f03b7d4813bca7)

